import logging, os

from datetime import datetime
from typing import List

from pydantic import BaseModel
from langgraph.graph.state import CompiledStateGraph
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain.chat_models import init_chat_model

from application.enums.status_enum import StatusEnum
from services.states.main_state import MainState
from infrastructure.repositories.subjects_repository import SubjectsRepository

class Topic(BaseModel):
    topic: str

class TopicList(BaseModel):
    topics: List[Topic]

parser = JsonOutputParser(pydantic_object = TopicList)

PROMPT = """
    # Especialista em gerar tÃ³picos a partir de conteÃºdos

    ## Contexto
    
    VocÃª receberÃ¡ uma lista de conteÃºdos variados (artigos, links, textos, resultados de pesquisa) capturados de pesquisas na web, onde cada item conterÃ¡:
    - TÃ­tulo (`title`);
    - URL (`url`);
    - ConteÃºdo completo ou resumo (`content`);
    - PontuaÃ§Ã£o de relevÃ¢ncia (`score`);
    - Texto bruto (`raw_content`);
    
    ## Tarefa
    
    Sua funÃ§Ã£o Ã© analisar todos os itens e gerar **uma listagem de tÃ³picos** que:
    1. Seja ordenado pelo conteÃºdo mais simples/base ao mais complexo/detalhado;
    2. Facilite a criaÃ§Ã£o de conteÃºdo coerente e completo;
    3. Agrupe conceitos relacionados e destaquem insights importantes;
    
    ## Objetivo
    
    Gerar **tÃ³picos claros, organizados e bem definidos** que reflitam os pontos mais importantes de todos os conteÃºdos analisados.
    - **Cada tÃ³pico deve ter obrigatoriamente um tÃ­tulo curto**, onde a ideia Ã© capturar a essÃªncia do assunto de forma concisa;  
    - Priorize relevÃ¢ncia e qualidade da informaÃ§Ã£o;
    - Use linguagem clara e objetiva;
    - NÃ£o invente informaÃ§Ãµes, baseie-se somente no que foi capturado;
    - Evite tÃ³picos muito amplos ou genÃ©ricos, foque em aspectos especÃ­ficos e Ãºteis;
    - Evite repetiÃ§Ãµes e sobreposiÃ§Ãµes;
    - Sua linguagem de saÃ­da Ã© em inglÃªs, mesmo que o conteÃºdo analisado esteja em outro idioma;
    - Gere entre 5 a 10 tÃ³picos, dependendo da quantidade e diversidade do conteÃºdo analisado;

    ## Formato da Resposta
    
    {format_instructions}
    
    ## ConteÃºdos
    
    {searches}
"""

def topics_generator_node(state: MainState, graph: CompiledStateGraph, config: dict) -> MainState:
    try:
        init_datetime: datetime = datetime.now()
        
        model = init_chat_model(
            model_provider = os.getenv("GOOGLE_MODEL_PROVIDER"),
            model = os.getenv("GOOGLE_MODEL"),
            api_key = os.getenv("GOOGLE_API_KEY"),
            timeout = float(os.getenv("GOOGLE_TIMEOUT")),
            max_retries = int(os.getenv("GOOGLE_MAX_RETRIES"))
        )
        
        promt_template = PromptTemplate(
            template = PROMPT, 
            input_variables = ["searches"],
            partial_variables = {"format_instructions": parser.get_format_instructions()}
        )
            
        chain = promt_template | model | parser
        
        response = chain.invoke({"searches": state.searches})
        
        state.topics = response["topics"]
        
        logging.info(f"ðŸŽ¯ topics_generator_node: {(datetime.now() - init_datetime).total_seconds()}")
        
        return state
    except Exception as ex:
        graph_state = graph.get_state(config)
        
        SubjectsRepository.update(id = state.subject_id, checkpoint_id = graph_state.config["configurable"]["checkpoint_id"], status = StatusEnum.ERROR.value)
        
        raise ex
